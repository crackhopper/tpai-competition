{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat competition/extractors/Base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a simple extractor\n",
    "!cat competition/extractors/Raw.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run existing extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import loadDataStore,loadAll\n",
    "\n",
    "from competition.extractors.Raw import Raw\n",
    "\n",
    "from config import extractedDir\n",
    "\n",
    "extractFile = 'raw.db'\n",
    "extractor= Raw()\n",
    "alldata = loadAll()\n",
    "\n",
    "extractor.run(alldata,extractedDir+extractFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import loadDataStore,loadAll\n",
    "\n",
    "from competition.extractors.Combine import Combine\n",
    "from competition.extractors.Merge import Merge\n",
    "from competition.extractors.Raw import Raw\n",
    "\n",
    "from config import extractedDir\n",
    "\n",
    "extractFile = 'raw_merge.db'\n",
    "extractor= Combine([Raw(),Merge(loadDataStore())])\n",
    "alldata = loadAll()\n",
    "\n",
    "extractor.run(alldata,extractedDir+extractFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import loadDataStore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "store = loadDataStore()\n",
    "train = store['train']\n",
    "dates = train['clickTime']\n",
    "dates = pd.DataFrame(dates//10000)\n",
    "dategrp = dates.groupby(by='clickTime').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k,v in dategrp.items():\n",
    "    print k,len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 交叉验证使用的样本\n",
    "from config import cvDB\n",
    "cvKey = 'cv_simple'\n",
    "cvStore=pd.HDFStore(cvDB)\n",
    "split_grps = [\n",
    "    ([17,18,19,20,21,22,23],[24]),\n",
    "    ([18,19,20,21,22,23,24],[25]),\n",
    "#    ([25,26,27,28],[29,30]),\n",
    "]\n",
    "cv = []\n",
    "cvgrp = []\n",
    "for tr_grp, te_grp in split_grps:\n",
    "    train_idx = []\n",
    "    for t in tr_grp:\n",
    "        train_idx.extend(dategrp[t])\n",
    "    test_idx = []\n",
    "    for t in te_grp:\n",
    "        test_idx.extend(dategrp[t])\n",
    "    cv.append((train_idx,test_idx))\n",
    "    cvgrp.append((tr_grp,te_grp))\n",
    "\n",
    "dfcv = pd.DataFrame(cv)\n",
    "cvStore[cvKey] = dfcv\n",
    "cvStore['grp_'+cvKey] = pd.DataFrame(cvgrp)\n",
    "\n",
    "cvStore.flush(fsync=True)\n",
    "dfcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# design and validate a extractor\n",
    "- get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import getTrainAndVal,loadAll\n",
    "extractFile = 'raw_merge.db'\n",
    "cvKey = 'cv_simple'\n",
    "cvSet = getTrainAndVal(extractFile,cvKey)\n",
    "all_data = loadAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX,trY,valX,valY = cvSet[0]\n",
    "print trX.shape,trY.shape\n",
    "print valX.shape,valY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trX,trY,valX,valY = cvSet[0]\n",
    "# print trX.shape,trY.shape\n",
    "# print valX.shape,valY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- design a extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def CvrStatisticsByKey(train_label,X,key):\n",
    "    dfCvr = train_label.groupby(key).apply(lambda df: np.mean(df[\"label\"])).reset_index()\n",
    "    dfCvr.columns=[key,key+'Cvr']\n",
    "    newX = pd.merge(X,dfCvr,on=key,how='left')\n",
    "    return newX\n",
    "\n",
    "def split_time(tm):\n",
    "    day=(tm//10000)%7\n",
    "    hour = (tm%10000)//100\n",
    "    minute = (tm%100)\n",
    "    return (day,hour,minute)\n",
    "\n",
    "def convertTime(df):\n",
    "    timeInfo = df.apply(lambda row: split_time(row['clickTime']), axis=1)\n",
    "    df['clickDay'],df['clickHour'],df['clickMin']=zip(*timeInfo)\n",
    "    return df\n",
    "\n",
    "dfTrain = convertTime(trX.copy())\n",
    "dfTrain['label']=trY.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _extract(X,y,all_data):\n",
    "    newX = convertTime(X)\n",
    "    newX = X\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'appID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'positionID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'connectionType')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'camgaignID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'count_act')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'clickDay')\n",
    "    del newX['clickTime']\n",
    "    del newX['appID']\n",
    "\n",
    "    return newX,y,all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_trX, e_trY, _ = _extract(trX, trY, all_data)\n",
    "e_valX, e_valY, _ = _extract(valX, valY, all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_trX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- new feature explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "#    'clickDay',\n",
    "#    'clickHour',\n",
    "#    'clickMin',\n",
    "#    'creativeIDCvr',\n",
    "    'appIDCvr',\n",
    "    'positionIDCvr',\n",
    "    'connectionTypeCvr',\n",
    "    'clickDayCvr',\n",
    "    'count_actCvr',\n",
    "    'camgaignIDCvr',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_trX[features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "for f in features:\n",
    "    figure()\n",
    "    col = e_trX[f].copy()\n",
    "    col = col.fillna(-1)\n",
    "    hist(col)\n",
    "    title(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlyCvr(object):\n",
    "    def fit(self,X,y):\n",
    "        return self\n",
    "    def predict(self,X):\n",
    "        return X['appCvr'].fillna(0)\n",
    "    \n",
    "from xgboost.sklearn import XGBModel\n",
    "\n",
    "# we only use XGBModel or Simple Classifier as OnlyCvr\n",
    "\n",
    "best_param = {\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 50,\n",
    "    'objective': 'binary:logistic',\n",
    "    'subsample': 0.8\n",
    "};\n",
    "\n",
    "#estimator = OnlyCvr()\n",
    "estimator = XGBModel(**best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator.fit(e_trX,e_trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from competition.models import official_score\n",
    "print -official_score(estimator,e_trX,e_trY)\n",
    "print -official_score(estimator,e_valX,e_valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "# only for xgb\n",
    "figure(figsize=(10,10))\n",
    "\n",
    "fimp = estimator.feature_importances_\n",
    "fnames=e_trX.columns\n",
    "\n",
    "idx = np.arange(len(fimp))\n",
    "barh(idx, fimp)\n",
    "yticks(idx+0.5,fnames)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we keep record here\n",
    "## record1 (no-merge)\n",
    "- 0.0999130021573\n",
    "- 0.108799880583"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## current best setting\n",
    "\n",
    "    newX = convertTime(X)\n",
    "    newX = X\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'appID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'positionID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'connectionType')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'camgaignID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'count_act')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'clickDay')\n",
    "    del newX['clickTime']\n",
    "    del newX['appID']\n",
    "- 0.0991358327441\n",
    "- 0.106815019252    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save and run the new extractor\n",
    "- save extractor into file\n",
    "- import and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile competition/extractors/StatsFeatures.py\n",
    "from competition.extractors.Base import BaseExtractor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def CvrStatisticsByKey(train_label,X,key):\n",
    "    dfCvr = train_label.groupby(key).apply(lambda df: np.mean(df[\"label\"])).reset_index()\n",
    "    dfCvr.columns=[key,key+'Cvr']\n",
    "    newX = pd.merge(X,dfCvr,on=key,how='left')\n",
    "    return newX\n",
    "\n",
    "def split_time(tm):\n",
    "    day=(tm//10000)%7\n",
    "    hour = (tm%10000)//100\n",
    "    minute = (tm%100)\n",
    "    return (day,minute,hour)\n",
    "\n",
    "def convertTime(df):\n",
    "    timeInfo = df.apply(lambda row: split_time(row['clickTime']), axis=1)\n",
    "    df['clickDay'],df['clickHour'],df['clickMin']=zip(*timeInfo)\n",
    "    return df\n",
    "\n",
    "def stats_extract(X,y,raw_data,dfTrain):\n",
    "    newX = convertTime(X)\n",
    "    newX = X\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'appID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'positionID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'connectionType')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'camgaignID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'count_act')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'clickDay')\n",
    "    del newX['clickTime']\n",
    "    del newX['appID']\n",
    "    return newX,y,raw_data\n",
    "\n",
    "class StatsFeatures(BaseExtractor):\n",
    "    def __init__(self,X,y):\n",
    "        self.dfTrain = convertTime(X.copy())\n",
    "        self.dfTrain['label']=y.copy()\n",
    "\n",
    "    def get_train(self,X,y,raw_data):\n",
    "        return self._extract(X,y,raw_data)\n",
    "\n",
    "    def get_test(self,X,y,raw_data):\n",
    "        return self._extract(X,y,raw_data)\n",
    "\n",
    "    def _extract(self,X,y,raw_data):\n",
    "        return stats_extract(X,y,raw_data,self.dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run extractor by loading from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import loadDataStore,loadAll\n",
    "\n",
    "from competition.extractors.Combine import Combine\n",
    "from competition.extractors.Wrapper import Wrapper\n",
    "from competition.extractors.StatsFeatures import StatsFeatures\n",
    "\n",
    "from config import extractedDir\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "inFile = 'raw_merge.db'\n",
    "ext = pd.HDFStore(os.path.join(extractedDir,inFile))\n",
    "trX = ext['trX']\n",
    "trY = ext['trY']\n",
    "teX = ext['teX']\n",
    "\n",
    "\n",
    "extractFile = 'raw_merge_stats.db'\n",
    "extractor= Combine([Wrapper(trX,trY,teX),StatsFeatures(trX,trY)])\n",
    "alldata = loadAll()\n",
    "\n",
    "extractor.run(alldata,extractedDir+extractFile)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate no-tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlyCvr(object):\n",
    "    def fit(self,X,y):\n",
    "        return self\n",
    "    def predict(self,X):\n",
    "        return X['appCvr'].fillna(0)\n",
    "    \n",
    "from xgboost.sklearn import XGBModel\n",
    "\n",
    "# we only use XGBModel or Simple Classifier as OnlyCvr\n",
    "\n",
    "best_param = {\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 50,\n",
    "    'objective': 'binary:logistic',\n",
    "    'subsample': 0.8\n",
    "};\n",
    "\n",
    "#estimator = OnlyCvr()\n",
    "estimator = XGBModel(**best_param)\n",
    "clf = estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import loadExtracted\n",
    "extractFile = 'raw_merge_stats.db'\n",
    "dset = loadExtracted(extractFile)\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(dset['trX'],dset['trY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import saveModel\n",
    "saveModel(clf,extractFile,estimator_name='XGB',para_name='_FE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make no-tune result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import loadModel\n",
    "extractFile = 'raw_merge_stats.db'\n",
    "clf=loadModel(extractFile,estimator_name='XGB',para_name='_FE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import predictResult\n",
    "predictResult(clf,extractFile,estimator_name='XGB',para_name='_FE') # feature engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls ./_results/raw_merge_stats.db-XGB_FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
