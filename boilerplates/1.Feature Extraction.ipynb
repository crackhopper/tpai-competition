{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# call a extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import store,raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from competition.extractors import Raw,Combine,SelectByClickTime\n",
    "from run_1_extract_features import extract_features\n",
    "\n",
    "extractFile = 'raw.db'\n",
    "extractor = Combine([Raw()])\n",
    "\n",
    "extract_features(extractor,extractFile,raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from competition.extractors import Raw,Combine,SelectByClickTime\n",
    "from run_1_extract_features import extract_features\n",
    "\n",
    "extractFile = 'train.db'\n",
    "extractor = Combine([Raw(),SelectByClickTime([170000,290000])])\n",
    "\n",
    "extract_features(extractor,extractFile,raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from competition.extractors import Raw,Combine,SelectByClickTime\n",
    "from run_1_extract_features import extract_features\n",
    "\n",
    "extractFile = 'val.db'\n",
    "extractor = Combine([Raw(),SelectByClickTime([300000,320000])])\n",
    "\n",
    "extract_features(extractor,extractFile,raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# design a extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import store,raw_data\n",
    "from extracted import loadFile\n",
    "\n",
    "fname = 'train.db'\n",
    "ext = loadFile(fname)\n",
    "trX = ext['trX']\n",
    "trY = ext['trY']\n",
    "\n",
    "fname = 'val.db'\n",
    "ext = loadFile(fname)\n",
    "valX = ext['trX']\n",
    "valY = ext['trY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def CvrStatisticsByKey(train_label,X,key):\n",
    "    dfCvr = train_label.groupby(key).apply(lambda df: np.mean(df[\"label\"])).reset_index()\n",
    "    dfCvr.columns=[key,key+'Cvr']\n",
    "    newX = pd.merge(X,dfCvr,on=key,how='left')\n",
    "    return newX\n",
    "\n",
    "def split_time(tm):\n",
    "    day=(tm//10000)%7\n",
    "    hour = (tm%10000)//100\n",
    "    minute = (tm%100)\n",
    "    return (day,minute,hour)\n",
    "\n",
    "def convertTime(df):\n",
    "    timeInfo = df.apply(lambda row: split_time(row['clickTime']), axis=1)\n",
    "    df['clickDay'],df['clickHour'],df['clickMin']=zip(*timeInfo)\n",
    "    return df\n",
    "\n",
    "dfTrain = convertTime(trX.copy())\n",
    "dfTrain['label']=trY.copy()\n",
    "\n",
    "def _extract(X,y,raw_data):\n",
    "    newX = convertTime(X)\n",
    "    newX = X\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'appID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'positionID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'connectionType')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'camgaignID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'count_act')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'clickDay')\n",
    "    del newX['clickTime']\n",
    "    del newX['appID']\n",
    "    return newX,y,raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX, trY, _ = _extract(trX, trY, raw_data)\n",
    "valX, valY, _ = _extract(valX, valY, raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlyCvr(object):\n",
    "    def fit(self,X,y):\n",
    "        return self\n",
    "    def predict(self,X):\n",
    "        return X['appCvr'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from xgboost.sklearn import XGBModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from competition.models import logloss\n",
    "\n",
    "import numpy as np\n",
    "def strip_feats_X(X,idx,dels):\n",
    "    X=X[idx]\n",
    "    for k in dels:\n",
    "        del X[k]\n",
    "    return X,idx\n",
    "\n",
    "def split_data_into_4_X(X):\n",
    "    act_null_idx = np.isnan(X['count_act'])\n",
    "    inst_null_idx = np.isnan(X['count_inst'])\n",
    "    # all information complete\n",
    "    idx1 = ~(act_null_idx | inst_null_idx)\n",
    "    del1 = []    \n",
    "    # lack of all other information\n",
    "    idx2 = (act_null_idx&inst_null_idx)\n",
    "    del2 = ['count_inst','appCate1_inst','count_act','appCate1_act']    \n",
    "    # only lack of act\n",
    "    idx3 = act_null_idx&(~idx2)\n",
    "    del3 = ['count_act','appCate1_act']    \n",
    "    # only lack of inst\n",
    "    idx4 = inst_null_idx&(~idx2)\n",
    "    del4 = ['count_inst','appCate1_inst']\n",
    "    return [strip_feats_X(X,idx1,del1),\n",
    "           strip_feats_X(X,idx2,del2),\n",
    "           strip_feats_X(X,idx3,del3),\n",
    "           strip_feats_X(X,idx4,del4),]\n",
    "    \n",
    "def split_data_into_4(X,y):\n",
    "    return [(_x,y[_idx]) for _x,_idx in split_data_into_4_X(X)]\n",
    "\n",
    "class FourEsts(object):\n",
    "    def __init__(self):\n",
    "        self.ests = [XGBModel(n_estimators=50,objective='reg:logistic'),\n",
    "                  XGBModel(n_estimators=50,objective='reg:logistic'),\n",
    "                  XGBModel(n_estimators=50,objective='reg:logistic'),\n",
    "                  XGBModel(n_estimators=50,objective='reg:logistic')]\n",
    "    def fit(self,X,y):\n",
    "        for i,(_x,_y) in enumerate(split_data_into_4(X,y)):\n",
    "            self.ests[i].fit(_x,_y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        y = np.zeros([X.shape[0]])\n",
    "        for i,(_x,_idx) in enumerate(split_data_into_4_X(X)):\n",
    "            _y = self.ests[i].predict(_x)\n",
    "            y[_idx] = _y\n",
    "        return y\n",
    "    def loss(self,X,y):\n",
    "        y = y.as_matrix()\n",
    "        res = []\n",
    "        for i,(_x,_idx) in enumerate(split_data_into_4_X(X)):\n",
    "            _y = self.ests[i].predict(_x)\n",
    "            res.append(logloss(y[_idx],_y))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = FourEsts()\n",
    "estimator = XGBModel(n_estimators=150,objective='reg:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator.fit(trX,trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#estimator.loss(valX,valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from competition.models import official_score\n",
    "print -official_score(estimator,trX,trY)\n",
    "print -official_score(estimator,valX,valY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## record1(origin)       \n",
    "- 0.104726901926  \n",
    "- 0.124660252014\n",
    "\n",
    "## record2(origin+cvr)  \n",
    "- 0.103728718243  \n",
    "- 0.127432079715\n",
    "\n",
    "## record2(use cvr)  \n",
    "- 0.109738338197  \n",
    "- 0.119089350834\n",
    "\n",
    "## record3(rf)\n",
    "- 0.23114836522\n",
    "- 1.15164827966\n",
    "\n",
    "## record4(split-time+xgb+cvr)\n",
    "- 0.103214516872\n",
    "- 0.117468540242\n",
    "\n",
    "## record5(split-time+xgb+appcvr+poscvr)\n",
    "- 0.100127016268\n",
    "- 0.120103391753\n",
    "\n",
    "## record6(above+appcate1_actcvr+est=50+logistic)\n",
    "- 0.101986737032\n",
    "- 0.116966472891\n",
    "\n",
    "## record7(above+connectionTypeCVR+est=50+logistic)\n",
    "- 0.101914773732\n",
    "- 0.116814070908\n",
    "\n",
    "## record7(above+connectionTypeCVR+camgaignIDCvr+est=50+logistic)\n",
    "- 0.100868704737\n",
    "- 0.115180648311\n",
    "\n",
    "## record8(all above + dayCvr)\n",
    "- 0.100868704737\n",
    "- 0.115180648311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "figure(figsize=(10,10))\n",
    "\n",
    "fimp = estimator.feature_importances_\n",
    "fnames=trX.columns\n",
    "\n",
    "idx = np.arange(len(fimp))\n",
    "barh(idx, fimp)\n",
    "yticks(idx+0.5,fnames)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "for i in range(4):\n",
    "    figure(figsize=(10,10))\n",
    "\n",
    "    fimp = estimator.ests[i].feature_importances_\n",
    "    fnames=trX.columns\n",
    "\n",
    "    idx = np.arange(len(fimp))\n",
    "    barh(idx, fimp)\n",
    "    yticks(idx+0.5,fnames)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save and run the new extractor\n",
    "- save extractor into file\n",
    "- modify and save `configCustom.py`\n",
    "- run `run_1_extract_features.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile competition/extractors/StatsFeatures.py\n",
    "from competition.extractors.Base import BaseExtractor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def CvrStatisticsByKey(train_label,X,key):\n",
    "    dfCvr = train_label.groupby(key).apply(lambda df: np.mean(df[\"label\"])).reset_index()\n",
    "    dfCvr.columns=[key,key+'Cvr']\n",
    "    newX = pd.merge(X,dfCvr,on=key,how='left')\n",
    "    return newX\n",
    "\n",
    "def split_time(tm):\n",
    "    day=(tm//10000)%7\n",
    "    hour = (tm%10000)//100\n",
    "    minute = (tm%100)\n",
    "    return (day,minute,hour)\n",
    "\n",
    "def convertTime(df):\n",
    "    timeInfo = df.apply(lambda row: split_time(row['clickTime']), axis=1)\n",
    "    df['clickDay'],df['clickHour'],df['clickMin']=zip(*timeInfo)\n",
    "    return df\n",
    "\n",
    "def stats_extract(X,y,raw_data,dfTrain):\n",
    "    newX = convertTime(X)\n",
    "    newX = X\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'appID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'positionID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'connectionType')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'camgaignID')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'count_act')\n",
    "    newX = CvrStatisticsByKey(dfTrain,newX,'clickDay')\n",
    "    del newX['clickTime']\n",
    "    del newX['appID']\n",
    "    return newX,y,raw_data\n",
    "\n",
    "class StatsFeatures(BaseExtractor):\n",
    "    def __init__(self,X,y):\n",
    "        self.dfTrain = convertTime(X.copy())\n",
    "        self.dfTrain['label']=y.copy()\n",
    "\n",
    "    def get_train(self,X,y,raw_data):\n",
    "        return self._extract(X,y,raw_data)\n",
    "\n",
    "    def get_test(self,X,y,raw_data):\n",
    "        return self._extract(X,y,raw_data)\n",
    "\n",
    "    def _extract(self,X,y,raw_data):\n",
    "        return stats_extract(X,y,raw_data,self.dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only run once\n",
    "!echo \"from StatsFeatures import StatsFeatures\" >> competition/extractors/__init__.py\n",
    "!cat competition/extractors/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile config1_rc.py\n",
    "# -*- coding:utf-8 -*-\n",
    "from competition.extractors import *\n",
    "\n",
    "extractDir = './_extracted/'\n",
    "extractFile = 'raw_stats.db'\n",
    "\n",
    "# extractor\n",
    "import pandas as pd\n",
    "import os\n",
    "inFile = 'raw.db'\n",
    "ext = pd.HDFStore(os.path.join(extractDir,inFile))\n",
    "trX = ext['trX']\n",
    "trY = ext['trY']\n",
    "teX = ext['teX']\n",
    "extractor = Combine([Wrapper(trX,trY,teX),StatsFeatures(trX,trY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run run_1_extract_features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from extracted import loadFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
